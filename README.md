# ML-Privacy-Papers
1. Privacy-preserving Prediction ![Theoretical]
* Abstract: 
Using aggregation to predict the output. So you train different models on different fractions of training data then you aggregate when providing the final answer, they proved the error bound in PAC and Agnostic learning (mostly for convex problems)



[![Theoretical](https://i.imgur.com/IP38qWp.png)]


[{
  "name" : "Uber Emojis",
  "source": "http://uber-site.com/",
  "copyright": "optional",
  "license": "?"
},{
  "url": "https://cloud.githubusercontent.com/assets/...1234.gif",
  "labels": "first emoji name label1 label2",
  "name": "first_emoji_name"
}]
